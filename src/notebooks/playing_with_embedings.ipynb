{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pasha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pasha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pasha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pasha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "2022-05-26 14:14:02.206193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from tqdm import trange\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "from src.preprocessing.corpus_preprocessor import CorpusPreprocessor\n",
    "from src.preprocessing.functions import *\n",
    "from src.preprocessing.consts import EMAIL_REGEX\n",
    "from src.ds_loaders.xsum import XSumLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test my ds loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/pasha/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bdba130a8e6482a851376581aaa42fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = XSumLoader()\n",
    "loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "orig_documents, summaries = loader.X_val, loader.y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(orig_documents[219])\n",
    "\n",
    "# print(loader.X_train[4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test my preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "preprocessor = CorpusPreprocessor(verbose=False).\\\n",
    "    add(to_lower()).\\\n",
    "    add(expand_contractions()).\\\n",
    "    add(replace_by_regex([(EMAIL_REGEX, \"EMAIL\")])).\\\n",
    "    add(remove_by_regex([r\"\\d\"])).\\\n",
    "    add(remove_symbols(string.punctuation)).\\\n",
    "    add(lemmatize()).\\\n",
    "    add(remove_words(set(stopwords.words('english'))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11332/11332 [00:03<00:00, 2897.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in trange(len(orig_documents)):\n",
    "    orig_documents[idx] = nltk.sent_tokenize(orig_documents[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(orig_documents[219])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11332/11332 [00:20<00:00, 540.43it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for idx in trange(len(orig_documents)):\n",
    "    doc = orig_documents[idx]\n",
    "    if len(doc) == 0:\n",
    "        summaries = summaries[:idx] + summaries[idx+1:]\n",
    "        continue\n",
    "    documents.append(preprocessor.transform(doc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test some embedings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
      "  1 2 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      "  0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 1 1 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0]]\n",
      "['allegedly' 'appearing' 'bail' 'bailey' 'bexley' 'bright' 'brother'\n",
      " 'charge' 'charged' 'charity' 'defender' 'denied' 'due' 'earlier' 'efe'\n",
      " 'elder' 'exreading' 'foundation' 'four' 'fraudulent' 'greater' 'jointly'\n",
      " 'july' 'kent' 'manchester' 'money' 'mr' 'nigerian' 'offence' 'old'\n",
      " 'place' 'raise' 'relates' 'relating' 'released' 'sam' 'sodje' 'sport'\n",
      " 'stand' 'stephen' 'took' 'trading' 'trial']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "cur_doc = documents[0]\n",
    "X = vectorizer.fit_transform(cur_doc)\n",
    "# print(cur_doc[3])\n",
    "print(X.toarray())\n",
    "\n",
    "print(vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18974499 0.         0.25241555 0.25241555 0.18974499\n",
      "  0.         0.         0.         0.         0.25241555 0.25241555\n",
      "  0.         0.25241555 0.         0.         0.         0.\n",
      "  0.         0.25241555 0.         0.25241555 0.         0.\n",
      "  0.         0.25241555 0.         0.25241555 0.         0.\n",
      "  0.18974499 0.50483109 0.         0.         0.         0.25241555\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.27898225\n",
      "  0.37112683 0.         0.37112683 0.         0.         0.\n",
      "  0.         0.         0.27898225 0.37112683 0.         0.\n",
      "  0.         0.         0.         0.37112683 0.         0.\n",
      "  0.         0.         0.37112683 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27898225 0.         0.         0.27898225 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.40389105 0.         0.40389105 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.30361166\n",
      "  0.         0.40389105 0.         0.         0.         0.\n",
      "  0.40389105 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.30361166 0.40389105\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.44150407 0.         0.         0.         0.         0.\n",
      "  0.         0.33188599 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33188599 0.\n",
      "  0.44150407 0.         0.44150407 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.44150407 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.30577703 0.2298577\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30577703 0.         0.2298577  0.         0.         0.\n",
      "  0.         0.         0.30577703 0.         0.30577703 0.30577703\n",
      "  0.30577703 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.30577703\n",
      "  0.         0.         0.30577703 0.2298577  0.         0.\n",
      "  0.30577703]\n",
      " [0.         0.         0.70710678 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.70710678 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "print(tfidf.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(36440, 1056600)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# print(documents[0])\n",
    "# tekenized0 = [sentence.split() for sentence in documents[0]]\n",
    "#\n",
    "model = Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n",
    "model.build_vocab(documents, progress_per=1000)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# model.save(\"./word2vec2.model\")\n",
    "\n",
    "\n",
    "# model = word2vec.Word2Vec(tekenized0, min_count=1)\n",
    "# model.pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[('also said wa enough affordable housing proposed added residential element wa contrary scottish planning policy resident would travel basic amenity service',\n  0.3110412657260895),\n ('foul john akinde barnet', 0.28199031949043274),\n ('conceded james mckeown', 0.2805235981941223),\n ('inquest continues', 0.27203214168548584),\n ('grateful thought prayer guiding next stop', 0.26940277218818665),\n ('last month human right group amnesty international said men boy died nigerian military custody detained suspected militant',\n  0.2688613533973694),\n ('police appealing witness', 0.26770326495170593),\n ('foul james perch queen park ranger', 0.2583902180194855),\n ('dob', 0.25739988684654236),\n ('take time', 0.2560594379901886)]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"laugh\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/pasha/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d64f0cacbb74e46a54860c17808d443"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = XSumLoader()\n",
    "loader.load()\n",
    "orig_documents, summaries = loader.X_val, loader.y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "preprocessor = CorpusPreprocessor(verbose=False).\\\n",
    "    add(to_lower()).\\\n",
    "    add(expand_contractions()).\\\n",
    "    add(replace_by_regex([(EMAIL_REGEX, \"EMAIL\")])).\\\n",
    "    add(remove_by_regex([r\"\\d\"])).\\\n",
    "    add(remove_symbols(string.punctuation.replace('.', ''))).\\\n",
    "    add(lemmatize()).\\\n",
    "    add(remove_words(set(stopwords.words('english'))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11332/11332 [00:17<00:00, 651.27it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for idx in trange(len(orig_documents)):\n",
    "    doc = orig_documents[idx]\n",
    "    if len(doc) == 0:\n",
    "        summaries = summaries[:idx] + summaries[idx+1:]\n",
    "        continue\n",
    "    documents.append(preprocessor.transform(doc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'Voges was forced to retire hurt on 86 after suffering the injury while batting during the County Championship draw with Somerset on 4 June.\\nMiddlesex hope to have the Australian back for their T20 Blast game against Hampshire at Lord\\'s on 3 August.\\nThe 37-year-old has scored 230 runs in four first-class games this season at an average of 57.50.\\n\"Losing Adam is naturally a blow as he contributes significantly to everything we do,\" director of cricket Angus Fraser said.\\n\"His absence, however, does give opportunities to other players who are desperate to play in the first XI.\\n\"In the past we have coped well without an overseas player and I expect us to do so now.\"\\nDefending county champions Middlesex are sixth in the Division One table, having drawn all four of their matches this season.\\nVoges retired from international cricket in February with a Test batting average of 61.87 from 31 innings, second only to Australian great Sir Donald Bradman\\'s career average of 99.94 from 52 Tests.'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_documents[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: Chris Poole - known as \"moot\" online - created the site in 2003.>, <Sentence: Mr Poole shared news of his new position on blogging site Tumblr.>)\n",
      "Chris Poole - known as \"moot\" online - created the site in 2003. Mr Poole shared news of his new position on blogging site Tumblr.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chris Poole - known as \"moot\" online - created the site in 2003.\n",
      "It has gone on to be closely associated with offensive and often illegal activity, including instances where the images of child abuse were shared.\n",
      "It was widely credited as being the first place where leaked images of nude celebrities were posted following 2014's well-publicised security breach affecting Apple's iCloud service. That incident prompted a policy change on the site.\n",
      "However, 4chan has also been the rallying point for many instances of online activism from the likes of Anonymous, the loosely organized hacktivism group.\n",
      "Mr Poole shared news of his new position on blogging site Tumblr.\n",
      "\"When meeting with current and former Googlers, I continually find myself drawn to their intelligence, passion, and enthusiasm - as well as a universal desire to share it with others.\"\n",
      "\"I'm also impressed by Google's commitment to enabling these same talented people to tackle some of the world's most interesting and important problems.\n",
      "He added: \"I can't wait to contribute my own experience from a dozen years of building online communities, and to begin the next chapter of my career at such an incredible company.\"\n",
      "Mr Poole stepped down as the administrator of 4chan in January 2015. Now he is expected to turn his attentions to Google's social networking efforts.\n",
      "His arrival was welcomed by Bradley Horowitz, the head of \"streams, photos and sharing\" at the search giant's floundering social network, Google+.\n",
      "\"I'm thrilled he's joining our team here at Google,\" Mr Horowitz said.\n",
      "\"Welcome Chris!ï»¿\"\n",
      "Several commentators described the appointment as \"unexpected\" but noted that Mr Poole's expertise with social media could prove useful to the search firm.\n",
      "Follow Dave Lee on Twitter @DaveLeeBBC and on Facebook\n"
     ]
    }
   ],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "txt = orig_documents[1]\n",
    "my_parser = PlaintextParser.from_string(txt ,Tokenizer('english'))\n",
    "summarizer = LexRankSummarizer()\n",
    "lexrank_summary = summarizer(my_parser.document, sentences_count=2)\n",
    "my_sum = str(lexrank_summary[0])\n",
    "orig_sum = summaries[1]\n",
    "# print(lexrank_summary)\n",
    "# print(\" \".join(list(map(lambda x: str(x), lexrank_summary))))\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(txt)\n",
    "# print(orig_documents[1])\n",
    "# print(lexrank_summary)\n",
    "# print(\". \".join(list(lexrank_summary)))\n",
    "# print(\". \".join(my_sum))\n",
    "# print(orig_sum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"['Voges\", 'was', 'forced', 'to', 'retire', 'hurt', 'on', '86', 'after', 'suffering', 'the', 'injury', 'while', 'batting', 'during', 'the', 'County', 'Championship', 'draw', 'with', 'Somerset', 'on', '4', 'June.']]\n",
      "[[['Middlesex', 'batsman', 'Adam', 'Voges', 'will', 'be', 'out', 'until', 'August', 'after', 'suffering', 'a', 'torn', 'calf', 'muscle', 'in', 'his', 'right', 'leg.']]]\n",
      "{'bleu': 0.0, 'precisions': [0.08333333333333333, 0.043478260869565216, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.263157894736842, 'translation_length': 24, 'reference_length': 19}\n",
      "0.03170289855072464\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "bleu = load_metric(\"bleu\")\n",
    "pred = [my_sum.split()]\n",
    "ref = [[orig_sum.split()]]\n",
    "print(pred)\n",
    "print(ref)\n",
    "print(bleu.compute(predictions=pred, references=ref))\n",
    "print(np.mean(bleu.compute(predictions=pred, references=ref)['precisions']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.5178107940302672, 'precisions': [0.8, 0.5], 'brevity_penalty': 0.8187307530779819, 'length_ratio': 0.8333333333333334, 'translation_length': 5, 'reference_length': 6}\n"
     ]
    }
   ],
   "source": [
    "bleu = load_metric(\"bleu\")\n",
    "\n",
    "pred = [\"I have thirty six years\".split()]\n",
    "ref = [[\n",
    "    \"I am thirty six years old\".split(),\n",
    "    # \"I am thirty six\".split()\n",
    "]]\n",
    "print(bleu.compute(predictions=pred, references=ref, max_order=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), mid=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), high=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)),\n",
      " 'rouge2': AggregateScore(low=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445), mid=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445), high=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445)),\n",
      " 'rougeL': AggregateScore(low=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), mid=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), high=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272)),\n",
      " 'rougeLsum': AggregateScore(low=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), mid=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272), high=Score(precision=0.8, recall=0.6666666666666666, fmeasure=0.7272727272727272))}\n",
      "'===================='\n",
      "AggregateScore(low=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445), mid=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445), high=Score(precision=0.5, recall=0.4, fmeasure=0.4444444444444445))\n",
      "0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rouge = load_metric(\"rouge\")\n",
    "result = rouge.compute(predictions=pred, references=ref)\n",
    "pprint(result)\n",
    "pprint(\"=\" * 20)\n",
    "print(result['rouge2'])\n",
    "pprint(result['rouge2'][1][2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from src.metrics import BLEU, ROUGE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-2: 0.5178107940302672\n",
      "<src.metrics.ROUGE.ROUGE object at 0x7fabb98c0520>: 0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "bm = BLEU(max_order=2)\n",
    "rm = ROUGE(subtype=\"rouge2\", submetric=\"fmeasure\")\n",
    "\n",
    "pred = [\"I have thirty six years\"]\n",
    "ref = [\"I am thirty six years old\"]\n",
    "bm.update_state(pred, ref)\n",
    "rm.update_state(pred, ref)\n",
    "print(f\"{bm}: {bm.result()}\")\n",
    "print(f\"{rm}: {float(rm.result())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 17:01:55.517661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import GloveCosineSimilarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Loaded GloVe embedings from /home/pasha/Documents/ML/ML_project_summarization/src/embedings/../../data/glove/glove.6B.100d.txt\n",
      "DEBUG: Loaded GloVe embedings from /home/pasha/Documents/ML/ML_project_summarization/src/embedings/../../data/glove/glove.6B.100d.txt\n",
      "0.9187776651788369\n"
     ]
    }
   ],
   "source": [
    "metric = GloveCosineSimilarity()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6254994309841915\n"
     ]
    }
   ],
   "source": [
    "pred = [\"I have thirty six years\"]\n",
    "ref = [\"I am thirty six years old\"]\n",
    "ref = [\"He is \"]\n",
    "metric.reset_state()\n",
    "metric.update_state(pred, ref)\n",
    "print(metric.result())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}